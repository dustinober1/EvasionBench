---
phase: 04-q-a-interaction-research-analyses
plan: "02"
type: execute
wave: 2
depends_on:
  - "01"
files_modified:
  - src/analysis/qa_semantic.py
  - scripts/analyze_qa_semantic.py
  - tests/test_qa_semantic_analysis.py
  - docs/analysis_workflow.md
autonomous: true
user_setup: []
must_haves:
  truths:
    - Q-A semantic similarity analysis runs reproducibly from scripts and outputs analysis-ready tables/charts.
    - Results include label-stratified similarity distributions tied to explicit evasion hypotheses.
    - Semantic artifacts are written into the phase-4 contract and indexed for downstream report generation.
  artifacts:
    - src/analysis/qa_semantic.py
    - scripts/analyze_qa_semantic.py
    - tests/test_qa_semantic_analysis.py
    - artifacts/analysis/phase4/semantic_similarity/*
  key_links:
    - scripts/analyze_qa_semantic.py invokes src/analysis/qa_semantic.py with deterministic model and preprocessing parameters.
    - semantic outputs include distribution tables, summary metrics, and hypothesis interpretation markdown/json.
    - docs/analysis_workflow.md documents semantic-analysis command usage and expected artifacts.
---

<objective>
Implement script-first question-answer semantic similarity analysis outputs.

Purpose: Satisfy `ANLY-05` with reproducible semantic-similarity evidence and interpretation notes for report inclusion.
Output: Semantic analysis module + CLI script + tests producing label-stratified, hypothesis-linked artifacts.
</objective>

<execution_context>
@/Users/dustinober/.codex/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.codex/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-q-a-interaction-research-analyses/04-RESEARCH.md
@.planning/phases/04-q-a-interaction-research-analyses/04-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build deterministic Q-A embedding and similarity pipeline</name>
  <files>src/analysis/qa_semantic.py, scripts/analyze_qa_semantic.py</files>
  <action>Implement preprocessing and pairwise question-answer embedding workflow with configurable but deterministic model settings and cosine similarity computation. Persist row-level similarity outputs and aggregate by-label summaries.</action>
  <verify>`python scripts/analyze_qa_semantic.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase4` writes semantic similarity tables without notebook dependencies.</verify>
  <done>Semantic similarity signals are computed reproducibly for all question-answer pairs and label cohorts.</done>
</task>

<task type="auto">
  <name>Task 2: Add hypothesis-linked summaries and publication-style visualizations</name>
  <files>src/analysis/qa_semantic.py, scripts/analyze_qa_semantic.py</files>
  <action>Create distribution/contrast plots and structured summary artifacts that map observed similarity patterns to explicit evasion hypotheses (for example relevance deflection, vague response behavior). Include effect direction and confidence notes.</action>
  <verify>`python scripts/analyze_qa_semantic.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase4 --emit-hypothesis-summary` creates charts plus summary markdown/json.</verify>
  <done>Phase-4 semantic findings are interpretation-ready and directly consumable by report generation.</done>
</task>

<task type="auto">
  <name>Task 3: Add semantic analysis tests for schema and determinism</name>
  <files>tests/test_qa_semantic_analysis.py</files>
  <action>Create tests for required output fields, deterministic behavior on fixed fixtures, and edge handling (empty text pairs, missing columns). Add at least one negative test for invalid input schema.</action>
  <verify>`pytest -q tests/test_qa_semantic_analysis.py` passes with positive and negative contract assertions.</verify>
  <done>Semantic analysis outputs are stable, validated, and safe for automated downstream usage.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python scripts/analyze_qa_semantic.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase4`
- [ ] `pytest -q tests/test_qa_semantic_analysis.py`
- [ ] `python -m json.tool artifacts/analysis/phase4/semantic_similarity/hypothesis_summary.json >/dev/null`
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- ANLY-05 semantic-similarity artifacts are reproducible and interpretation-ready
</success_criteria>

<output>
After completion, create `.planning/phases/04-q-a-interaction-research-analyses/04-02-SUMMARY.md`
</output>
