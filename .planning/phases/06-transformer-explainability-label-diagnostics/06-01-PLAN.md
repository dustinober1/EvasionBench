---
phase: 06-transformer-explainability-label-diagnostics
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/models.py
  - scripts/run_transformer_baselines.py
  - dvc.yaml
  - Makefile
  - tests/test_transformer_baseline_contract.py
autonomous: true
user_setup: []
must_haves:
  truths:
    - Transformer classifier training runs reproducibly on local hardware (Mac M1 compatible).
    - Every transformer run writes phase-5 compatible evaluation artifacts plus model/tokenizer checkpoints.
    - MLflow logs transformer model with proper flavor and registers best model.
    - DVC stages and Make targets expose deterministic transformer training commands.
  artifacts:
    - scripts/run_transformer_baselines.py
    - src/models.py (transformer training functions)
    - dvc.yaml (phase6_transformer stage)
    - Makefile (model-phase6 target)
    - tests/test_transformer_baseline_contract.py
  key_links:
    - scripts/run_transformer_baselines.py invokes DistilBERT fine-tuning via Hugging Face Trainer API.
    - src/models.py exposes train_transformer() function with hardware detection and batch size adjustment.
    - MLflow autologging captures transformer params/metrics; explicit log_model() registers model.
    - DVC stage depends on prepared data and outputs model artifacts compatible with phase-5 contract.
---

<objective>
Establish transformer baseline training with Hugging Face DistilBERT for binary evasiveness classification.

Purpose: deliver a strong transformer baseline while maintaining script-first reproducibility and artifact contract compatibility with Phase 5.
Output: transformer training script, model checkpoints, MLflow-registered models, and contract validation tests.
</objective>

<execution_context>
@/home/dusitnober/.claude/get-shit-done/workflows/execute-plan.md
@/home/dusitnober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-transformer-explainability-label-diagnostics/06-RESEARCH.md
@.planning/phases/05-classical-baseline-modeling/05-01-SUMMARY.md
@scripts/run_classical_baselines.py
@src/models.py
@src/evaluation.py
@dvc.yaml
@Makefile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement DistilBERT training with hardware-aware configuration</name>
  <files>src/models.py, scripts/run_transformer_baselines.py</files>
  <action>Add train_transformer() function to src/models.py that:
- Loads distilbert-base-uncased model and tokenizer from Hugging Face
- Detects CPU vs GPU and adjusts batch size accordingly (16 for GPU, 4 for CPU)
- Uses gradient checkpointing and mixed precision (fp16) to reduce memory
- Accepts standard args: frame, target_col, random_state, test_size, model_name, max_epochs, learning_rate
- Tokenizes Q+A text with 512 token limit and proper padding/truncation
- Returns trained model, tokenizer, trainer, eval results, and split metadata

Create scripts/run_transformer_baselines.py that:
- Mirrors run_classical_baselines.py CLI structure for consistency
- Supports --model-name (default: distilbert-base-uncased), --max-epochs (default: 3), --learning-rate (default: 2e-5)
- Calls train_transformer() and writes evaluation artifacts via write_evaluation_artifacts()
- Uses MLflow transformers.autolog() and explicit log_model() for registration
- Handles CPU-only fallback gracefully with appropriate batch sizes

DO NOT use BERT-base (too large for M1). DO NOT use custom training loops (use Trainer API).</action>
  <verify>`python scripts/run_transformer_baselines.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/models/phase6/transformer --max-epochs 1 --learning-rate 2e-5` completes without GPU.</verify>
  <done>DistilBERT baseline trains reproducibly on local hardware with phase-5 compatible artifacts.</done>
</task>

<task type="auto">
  <name>Task 2: Add MLflow transformer registration and model checkpointing</name>
  <files>scripts/run_transformer_baselines.py</files>
  <action>Extend run_transformer_baselines.py to:
- Enable mlflow.transformers.autolog() before training for automatic param/metric capture
- Save model checkpoints with trainer.save_model() to output directory
- Use mlflow.transformers.log_model() with task="text-classification" for proper serialization
- Register best model with mlflow.register_model() using model name "evasionbench-distilbert"
- Log custom metrics: accuracy, f1_macro, precision_macro, recall_macro
- Include git SHA, split metadata, and training config in run tags

Follow the MLflow transformers pattern from RESEARCH.md (log both model and tokenizer together).</action>
  <verify>After run, MLflow UI shows registered model with artifacts including model/config/tokenizer files.</verify>
  <done>Transformer models are versioned and registered for downstream API/dashboard serving.</done>
</task>

<task type="auto">
  <name>Task 3: Wire DVC stage, add Make target, and write contract tests</name>
  <files>dvc.yaml, Makefile, tests/test_transformer_baseline_contract.py</files>
  <action>Add to dvc.yaml:
- phase6_transformer stage with cmd invoking run_transformer_baselines.py
- Depends on data/processed/evasionbench_prepared.parquet
- Outputs to artifacts/models/phase6/transformer with evaluation artifacts

Add to Makefile:
- model-phase6 target calling transformer script with canonical args

Create tests/test_transformer_baseline_contract.py:
- Validate required output files exist (metrics.json, classification_report.json, etc.)
- Check MLflow run contains required params/metrics/tags
- Verify model directory contains pytorch_model.bin, config.json, tokenizer files
- Test reproducibility with fixed random state

Follow Phase 5 test patterns (test_classical_baseline_contract.py).</action>
  <verify>`pytest -q tests/test_transformer_baseline_contract.py` passes all contract validations.</verify>
  <done>Transformer training is wired into DVC/Make and validated by contract tests.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pytest -q tests/test_transformer_baseline_contract.py`
- [ ] `python scripts/run_transformer_baselines.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/models/phase6/transformer --max-epochs 1`
- [ ] `dvc repro phase6_transformer` (if DVC available)
- [ ] MLflow UI shows registered transformer model
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Transformer trains successfully on CPU (M1 compatible)
- Evaluation artifacts match Phase 5 contract schema
- MLflow model registry contains transformer version
</success_criteria>

<output>
After completion, create `.planning/phases/06-transformer-explainability-label-diagnostics/06-01-SUMMARY.md`
</output>
