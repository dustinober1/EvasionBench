---
phase: 03-statistical-linguistic-core-analyses
plan: "03"
type: execute
wave: 2
depends_on:
  - "01"
files_modified:
  - src/analysis/lexical.py
  - scripts/analyze_lexical.py
  - tests/test_lexical_analysis.py
  - docs/analysis_workflow.md
autonomous: true
user_setup: []
must_haves:
  truths:
    - Lexical feature comparisons are reproducible and stratified by evasiveness label.
    - N-gram analyses produce stable ranking tables and plot outputs suitable for publication/reporting.
    - Lexical artifacts are written into the shared phase-3 contract and available for report build consumption.
  artifacts:
    - src/analysis/lexical.py
    - scripts/analyze_lexical.py
    - tests/test_lexical_analysis.py
    - artifacts/analysis/phase3/lexical/*
  key_links:
    - scripts/analyze_lexical.py invokes src/analysis/lexical.py with fixed vectorizer/tokenization parameters.
    - lexical analysis writes per-label lexical summary tables and top n-gram artifacts with stable sort rules.
    - docs/analysis_workflow.md documents lexical script usage and expected artifacts.
---

<objective>
Implement script-first lexical and n-gram analyses by evasiveness label.

Purpose: Satisfy `ANLY-03` with reproducible lexical comparisons that are report-ready and deterministic.
Output: Lexical analysis module + CLI script + tests + documented artifact contract.
</objective>

<execution_context>
@/Users/dustinober/.codex/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.codex/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-statistical-linguistic-core-analyses/03-RESEARCH.md
@.planning/phases/03-statistical-linguistic-core-analyses/03-01-SUMMARY.md
@notebooks/02_linguistic_patterns.ipynb
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build lexical feature extraction by label</name>
  <files>src/analysis/lexical.py, scripts/analyze_lexical.py</files>
  <action>Implement deterministic lexical summaries (token counts, type-token ratio, average word length, selected vocabulary richness metrics) grouped by evasiveness label. Persist outputs as CSV/JSON tables in the lexical artifact directory.</action>
  <verify>`python scripts/analyze_lexical.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3 --sections lexical` writes lexical summary tables with label-stratified rows.</verify>
  <done>Lexical summary features are reproducibly generated for each evasiveness label.</done>
</task>

<task type="auto">
  <name>Task 2: Add top n-gram analysis and publication-style visual outputs</name>
  <files>src/analysis/lexical.py, scripts/analyze_lexical.py</files>
  <action>Use fixed `CountVectorizer` settings to compute top unigrams and bigrams per label, then emit ranking tables and one or more publication-ready figures (for example top-k bar charts). Enforce deterministic tie-breaking and sorting.</action>
  <verify>`python scripts/analyze_lexical.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3 --sections ngrams` produces unigram/bigram tables and figures for each label.</verify>
  <done>N-gram comparisons are reproducible and interpretation-ready for report integration.</done>
</task>

<task type="auto">
  <name>Task 3: Add lexical analysis tests for reproducibility and schema contracts</name>
  <files>tests/test_lexical_analysis.py</files>
  <action>Create tests that assert output schema, deterministic ordering for fixed fixtures, and behavior on edge cases (empty/short texts). Include at least one negative test for invalid input schema.</action>
  <verify>`pytest -q tests/test_lexical_analysis.py` passes and validates deterministic lexical/n-gram outputs.</verify>
  <done>Lexical pipeline quality is test-backed and safe for automation.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python scripts/analyze_lexical.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3`
- [ ] `pytest -q tests/test_lexical_analysis.py`
- [ ] `python -m json.tool artifacts/analysis/phase3/lexical/top_ngrams.json >/dev/null`
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- ANLY-03 lexical/n-gram artifacts are reproducible and report-consumable
</success_criteria>

<output>
After completion, create `.planning/phases/03-statistical-linguistic-core-analyses/03-03-SUMMARY.md`
</output>
