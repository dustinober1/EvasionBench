---
phase: 03-statistical-linguistic-core-analyses
plan: "02"
type: execute
wave: 2
depends_on:
  - "01"
files_modified:
  - src/analysis/core_stats.py
  - scripts/analyze_core_stats.py
  - tests/test_core_stats_analysis.py
  - docs/analysis_workflow.md
autonomous: true
user_setup: []
must_haves:
  truths:
    - Class distribution and data-quality statistics are generated as publication-ready tables and figures.
    - Question/answer length analyses include statistical significance tests and interpretation-ready summaries.
    - Core analysis outputs are stratified by evasiveness label and stored in phase-3 artifact paths.
  artifacts:
    - src/analysis/core_stats.py
    - scripts/analyze_core_stats.py
    - tests/test_core_stats_analysis.py
    - artifacts/analysis/phase3/core_stats/*
  key_links:
    - scripts/analyze_core_stats.py calls src/analysis/core_stats.py and writes both tabular and plotted outputs.
    - Statistical tests (Kruskal/Mann-Whitney) are persisted with p-values, sample sizes, and interpretation text.
    - Artifact index entries from plan 01 include core-stats outputs for report-phase discovery.
---

<objective>
Implement publication-grade core EDA and length-statistics analysis outputs.

Purpose: Satisfy `ANLY-01` and `ANLY-02` with deterministic script-generated tables/figures and significance test summaries.
Output: Core stats module + CLI script + tests producing report-consumable artifacts by evasiveness label.
</objective>

<execution_context>
@/Users/dustinober/.codex/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.codex/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-statistical-linguistic-core-analyses/03-RESEARCH.md
@.planning/phases/03-statistical-linguistic-core-analyses/03-01-SUMMARY.md
@notebooks/01_data_quality_and_statistics.ipynb
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build deterministic core EDA aggregations and quality tables</name>
  <files>src/analysis/core_stats.py, scripts/analyze_core_stats.py</files>
  <action>Implement class distribution, missingness, duplicate-rate, and label-stratified quality summary tables from prepared parquet input. Emit CSV/JSON tables and at least one publication-style chart (label distribution) with deterministic ordering and formatting.</action>
  <verify>`python scripts/analyze_core_stats.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3` writes class/quality tables and figure files.</verify>
  <done>Core report-ready EDA artifacts are generated by script without manual notebook steps.</done>
</task>

<task type="auto">
  <name>Task 2: Add length distribution analyses with significance testing</name>
  <files>src/analysis/core_stats.py, scripts/analyze_core_stats.py</files>
  <action>Compute question and answer length distributions by label, generate distribution/boxplot figures, and run non-parametric significance tests (`kruskal`, `mannwhitneyu`) aligned with phase hypotheses. Persist structured test results and short interpretation summaries.</action>
  <verify>`python scripts/analyze_core_stats.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3 --sections lengths` emits statistical test JSON/Markdown and corresponding length figures.</verify>
  <done>Length analyses include both statistical evidence and interpretation-ready outputs for report inclusion.</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for artifact schema and statistical output guarantees</name>
  <files>tests/test_core_stats_analysis.py</files>
  <action>Create tests that validate required columns/keys in generated tables, presence and shape of statistical test output fields, and deterministic behavior for fixed fixtures. Include at least one negative assertion for missing required input columns.</action>
  <verify>`pytest -q tests/test_core_stats_analysis.py` passes with positive and negative contract checks.</verify>
  <done>Core stats outputs are reliable, schema-checked, and safe for downstream report automation.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python scripts/analyze_core_stats.py --input data/processed/evasionbench_prepared.parquet --output-root artifacts/analysis/phase3`
- [ ] `pytest -q tests/test_core_stats_analysis.py`
- [ ] `python -m json.tool artifacts/analysis/phase3/core_stats/length_tests.json >/dev/null`
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- ANLY-01 and ANLY-02 evidence artifacts are generated and reproducible
</success_criteria>

<output>
After completion, create `.planning/phases/03-statistical-linguistic-core-analyses/03-02-SUMMARY.md`
</output>
