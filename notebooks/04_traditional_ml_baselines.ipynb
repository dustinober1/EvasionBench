{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b40f80",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (649255565.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    Comprehensive baseline modeling for evasion detection using:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 04 - Traditional ML Baselines\n",
    "\n",
    "## Overview\n",
    "Comprehensive baseline modeling for evasion detection using:\n",
    "1. TF-IDF + Logistic Regression (answer-only, question-only, combined)\n",
    "2. TF-IDF + XGBoost with feature importance\n",
    "3. Engineered linguistic features + models\n",
    "4. Hybrid models (TF-IDF + engineered features)\n",
    "5. Class imbalance handling strategies\n",
    "\n",
    "## Experimental Setup\n",
    "- Stratified 80/10/10 train/val/test splits (seed=42)\n",
    "- MLflow experiment tracking\n",
    "- Cross-validation on train+val\n",
    "- Final test set evaluation\n",
    "\n",
    "## Outputs\n",
    "- Baseline performance comparison table\n",
    "- Feature importance visualizations\n",
    "- Best traditional baseline model saved\n",
    "- Comprehensive summary of findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "proj_root = pathlib.Path('..').resolve()\n",
    "if str(proj_root) not in sys.path:\n",
    "    sys.path.insert(0, str(proj_root))\n",
    "\n",
    "# Core imports\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, f1_score, \n",
    "    precision_score, recall_score, accuracy_score,\n",
    "    roc_auc_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ XGBoost not available. Install with: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# Imbalanced-learn\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ imbalanced-learn not available. Install with: pip install imbalanced-learn\")\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "\n",
    "# NLP libraries\n",
    "import spacy\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "try:\n",
    "    import textstat\n",
    "    TEXTSTAT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ textstat not available. Install with: pip install textstat\")\n",
    "    TEXTSTAT_AVAILABLE = False\n",
    "\n",
    "# MLflow\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ MLflow not available. Install with: pip install mlflow\")\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "# Project utilities\n",
    "try:\n",
    "    from src.utils import set_seed\n",
    "except Exception as e:\n",
    "    print(f'Warning: could not import src.utils.set_seed: {e}')\n",
    "    def set_seed(seed=42):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "# Set random seed\n",
    "set_seed(42)\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('notebooks/figures', exist_ok=True)\n",
    "os.makedirs('models/baseline_traditional', exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: DATA LOADING AND TRAIN/VAL/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SECTION 2: DATA LOADING AND SPLITTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\nLoading dataset FutureMa/EvasionBench...\")\n",
    "ds = load_dataset(\"FutureMa/EvasionBench\")\n",
    "if isinstance(ds, dict):\n",
    "    ds = ds[list(ds.keys())[0]]\n",
    "df = ds.to_pandas()\n",
    "print(f\"✅ Dataset loaded: {df.shape[0]:,} samples\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"  Columns: {df.columns.tolist()}\")\n",
    "print(f\"  Label distribution:\")\n",
    "label_counts = df['eva4b_label'].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"    {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Create stratified 80/10/10 split\n",
    "print(\"\\nCreating stratified 80/10/10 train/val/test split...\")\n",
    "\n",
    "# First split: 80% train, 20% temp\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['eva4b_label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 10% val, 10% test (from the 20% temp)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_df['eva4b_label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Split complete:\")\n",
    "print(f\"  Train: {len(train_df):,} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df):,} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df):,} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nLabel distribution verification:\")\n",
    "for split_name, split_df in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for label in ['direct', 'intermediate', 'fully_evasive']:\n",
    "        count = (split_df['eva4b_label'] == label).sum()\n",
    "        pct = count / len(split_df) * 100\n",
    "        print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['direct', 'intermediate', 'fully_evasive'])\n",
    "\n",
    "y_train = label_encoder.transform(train_df['eva4b_label'])\n",
    "y_val = label_encoder.transform(val_df['eva4b_label'])\n",
    "y_test = label_encoder.transform(test_df['eva4b_label'])\n",
    "\n",
    "print(f\"\\n✅ Labels encoded: {label_encoder.classes_}\")\n",
    "\n",
    "# Prepare text data\n",
    "X_train_answers = train_df['answer'].values\n",
    "X_val_answers = val_df['answer'].values\n",
    "X_test_answers = test_df['answer'].values\n",
    "\n",
    "X_train_questions = train_df['question'].values\n",
    "X_val_questions = val_df['question'].values\n",
    "X_test_questions = test_df['question'].values\n",
    "\n",
    "# Combined Q+A\n",
    "X_train_combined = train_df['question'] + \" [SEP] \" + train_df['answer']\n",
    "X_val_combined = val_df['question'] + \" [SEP] \" + val_df['answer']\n",
    "X_test_combined = test_df['question'] + \" [SEP] \" + test_df['answer']\n",
    "\n",
    "print(f\"\\n✅ Text data prepared\")\n",
    "print(f\"  Sample answer: {X_train_answers[0][:100]}...\")\n",
    "print(f\"  Sample question: {X_train_questions[0][:100]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: FEATURE ENGINEERING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SECTION 3: FEATURE ENGINEERING FUNCTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
    "    print(\"✅ spaCy model loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ spaCy model not available: {e}\")\n",
    "    nlp = None\n",
    "\n",
    "# Hedging and certainty lexicons\n",
    "HEDGE_WORDS = {\n",
    "    'might', 'could', 'possibly', 'maybe', 'perhaps', 'potentially',\n",
    "    'approximately', 'roughly', 'about', 'around', 'somewhat',\n",
    "    'uncertain', 'unsure', 'not certain', 'not sure', 'hard to say',\n",
    "    'depends', 'various', 'a bit', 'to some extent', 'relatively',\n",
    "    'fairly', 'quite', 'rather', 'somewhat', 'allegedly', 'apparently'\n",
    "}\n",
    "\n",
    "CERTAINTY_WORDS = {\n",
    "    'definitely', 'certainly', 'exactly', 'precisely', 'absolutely',\n",
    "    'clearly', 'undoubtedly', 'undisputably', 'surely', 'guarantee',\n",
    "    'confirm', 'assure', 'always', 'never', 'every', 'all'\n",
    "}\n",
    "\n",
    "DEFLECTION_PHRASES = {\n",
    "    'not sure', 'hard to say', 'depends on', 'difficult to predict',\n",
    "    \"can't say\", 'unclear at this time', 'remains to be seen',\n",
    "    'too early to tell', 'premature to', 'would not want to speculate'\n",
    "}\n",
    "\n",
    "def extract_text_length_features(text):\n",
    "    \"\"\"Extract basic text length features.\"\"\"\n",
    "    return {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'sentence_count': text.count('.') + text.count('!') + text.count('?'),\n",
    "        'avg_word_length': np.mean([len(w) for w in text.split()]) if text.split() else 0,\n",
    "    }\n",
    "\n",
    "def extract_readability_features(text):\n",
    "    \"\"\"Extract readability scores.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    if TEXTSTAT_AVAILABLE:\n",
    "        try:\n",
    "            features['flesch_ease'] = textstat.flesch_reading_ease(text)\n",
    "            features['flesch_kincaid'] = textstat.flesch_kincaid_grade(text)\n",
    "            features['smog'] = textstat.smog_index(text)\n",
    "            features['ari'] = textstat.automated_readability_index(text)\n",
    "        except:\n",
    "            features['flesch_ease'] = 0\n",
    "            features['flesch_kincaid'] = 0\n",
    "            features['smog'] = 0\n",
    "            features['ari'] = 0\n",
    "    else:\n",
    "        features['flesch_ease'] = 0\n",
    "        features['flesch_kincaid'] = 0\n",
    "        features['smog'] = 0\n",
    "        features['ari'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_sentiment_features(text):\n",
    "    \"\"\"Extract sentiment scores using TextBlob.\"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return {\n",
    "        'sentiment_polarity': blob.sentiment.polarity,\n",
    "        'sentiment_subjectivity': blob.sentiment.subjectivity,\n",
    "    }\n",
    "\n",
    "def extract_hedging_features(text):\n",
    "    \"\"\"Extract hedging and certainty word counts.\"\"\"\n",
    "    words = set(text.lower().split())\n",
    "    \n",
    "    hedge_count = sum(1 for word in HEDGE_WORDS if word in text.lower())\n",
    "    certainty_count = sum(1 for word in CERTAINTY_WORDS if word in text.lower())\n",
    "    deflection_count = sum(1 for phrase in DEFLECTION_PHRASES if phrase in text.lower())\n",
    "    \n",
    "    word_count = len(text.split())\n",
    "    \n",
    "    return {\n",
    "        'hedge_word_count': hedge_count,\n",
    "        'certainty_word_count': certainty_count,\n",
    "        'deflection_phrase_count': deflection_count,\n",
    "        'hedge_ratio': hedge_count / word_count if word_count > 0 else 0,\n",
    "        'certainty_ratio': certainty_count / word_count if word_count > 0 else 0,\n",
    "    }\n",
    "\n",
    "def extract_pos_features(text, nlp_model=nlp):\n",
    "    \"\"\"Extract POS tag ratios using spaCy.\"\"\"\n",
    "    if nlp_model is None:\n",
    "        return {\n",
    "            'adj_ratio': 0, 'adv_ratio': 0, 'noun_ratio': 0,\n",
    "            'verb_ratio': 0, 'propn_ratio': 0\n",
    "        }\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    pos_counts = Counter([token.pos_ for token in doc])\n",
    "    total = len(doc)\n",
    "    \n",
    "    return {\n",
    "        'adj_ratio': pos_counts.get('ADJ', 0) / total if total > 0 else 0,\n",
    "        'adv_ratio': pos_counts.get('ADV', 0) / total if total > 0 else 0,\n",
    "        'noun_ratio': pos_counts.get('NOUN', 0) / total if total > 0 else 0,\n",
    "        'verb_ratio': pos_counts.get('VERB', 0) / total if total > 0 else 0,\n",
    "        'propn_ratio': pos_counts.get('PROPN', 0) / total if total > 0 else 0,\n",
    "    }\n",
    "\n",
    "def extract_entity_features(text, nlp_model=nlp):\n",
    "    \"\"\"Extract named entity counts.\"\"\"\n",
    "    if nlp_model is None:\n",
    "        return {\n",
    "            'org_count': 0, 'money_count': 0, 'percent_count': 0,\n",
    "            'number_count': 0, 'total_entities': 0\n",
    "        }\n",
    "    \n",
    "    # Enable NER for this\n",
    "    nlp_ner = spacy.load(\"en_core_web_sm\", disable=['parser'])\n",
    "    doc = nlp_ner(text)\n",
    "    \n",
    "    entity_counts = Counter([ent.label_ for ent in doc.ents])\n",
    "    \n",
    "    return {\n",
    "        'org_count': entity_counts.get('ORG', 0),\n",
    "        'money_count': entity_counts.get('MONEY', 0),\n",
    "        'percent_count': entity_counts.get('PERCENT', 0),\n",
    "        'number_count': entity_counts.get('CARDINAL', 0) + entity_counts.get('QUANTITY', 0),\n",
    "        'total_entities': len(doc.ents),\n",
    "    }\n",
    "\n",
    "def extract_all_features(question, answer, include_q_features=True):\n",
    "    \"\"\"Extract all engineered features for a Q-A pair.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Answer features\n",
    "    answer_length = extract_text_length_features(answer)\n",
    "    for k, v in answer_length.items():\n",
    "        features[f'answer_{k}'] = v\n",
    "    \n",
    "    answer_readability = extract_readability_features(answer)\n",
    "    for k, v in answer_readability.items():\n",
    "        features[f'answer_{k}'] = v\n",
    "    \n",
    "    answer_sentiment = extract_sentiment_features(answer)\n",
    "    for k, v in answer_sentiment.items():\n",
    "        features[f'answer_{k}'] = v\n",
    "    \n",
    "    answer_hedging = extract_hedging_features(answer)\n",
    "    for k, v in answer_hedging.items():\n",
    "        features[f'answer_{k}'] = v\n",
    "    \n",
    "    if nlp:\n",
    "        answer_pos = extract_pos_features(answer)\n",
    "        for k, v in answer_pos.items():\n",
    "            features[f'answer_{k}'] = v\n",
    "    \n",
    "    # Question features (optional)\n",
    "    if include_q_features:\n",
    "        question_length = extract_text_length_features(question)\n",
    "        for k, v in question_length.items():\n",
    "            features[f'question_{k}'] = v\n",
    "        \n",
    "        question_sentiment = extract_sentiment_features(question)\n",
    "        for k, v in question_sentiment.items():\n",
    "            features[f'question_{k}'] = v\n",
    "    \n",
    "    # Q-A interaction features\n",
    "    features['length_ratio'] = features.get('answer_word_count', 1) / max(features.get('question_word_count', 1), 1)\n",
    "    features['sentiment_diff'] = abs(\n",
    "        features.get('answer_sentiment_polarity', 0) - \n",
    "        features.get('question_sentiment_polarity', 0)\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"✅ Feature engineering functions defined\")\n",
    "print(f\"   Expected feature count: ~30 features per Q-A pair\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: TF-IDF BASELINES (LOGISTIC REGRESSION)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SECTION 4: TF-IDF + LOGISTIC REGRESSION BASELINES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize MLflow\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment(\"EvasionBench_Traditional_ML_Baselines\")\n",
    "    print(\"✅ MLflow experiment initialized\")\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                   model_name, feature_type):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'macro_f1': f1_score(y_val, y_val_pred, average='macro'),\n",
    "        'weighted_f1': f1_score(y_val, y_val_pred, average='weighted'),\n",
    "    }\n",
    "    \n",
    "    test_metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'macro_f1': f1_score(y_test, y_test_pred, average='macro'),\n",
    "        'weighted_f1': f1_score(y_test, y_test_pred, average='weighted'),\n",
    "    }\n",
    "    \n",
    "    # Per-class F1\n",
    "    per_class_f1 = f1_score(y_test, y_test_pred, average=None)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'feature_type': feature_type,\n",
    "        'val_metrics': val_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'per_class_f1': per_class_f1,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# --- 4.1 Answer-only TF-IDF + Logistic Regression ---\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.1: Answer-only TF-IDF + Logistic Regression\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create TF-IDF features\n",
    "tfidf_answer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf_answer = tfidf_answer.fit_transform(X_train_answers)\n",
    "X_val_tfidf_answer = tfidf_answer.transform(X_val_answers)\n",
    "X_test_tfidf_answer = tfidf_answer.transform(X_test_answers)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf_answer.shape}\")\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_answer = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result_lr_answer = evaluate_model(\n",
    "    lr_answer, X_train_tfidf_answer, y_train,\n",
    "    X_val_tfidf_answer, y_val, X_test_tfidf_answer, y_test,\n",
    "    \"Logistic Regression\", \"TF-IDF (Answer-only)\"\n",
    ")\n",
    "\n",
    "results.append(result_lr_answer)\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  Accuracy:  {result_lr_answer['val_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro-F1:  {result_lr_answer['val_metrics']['macro_f1']:.4f}\")\n",
    "print(f\"  Weighted-F1: {result_lr_answer['val_metrics']['weighted_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Accuracy:  {result_lr_answer['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro-F1:  {result_lr_answer['test_metrics']['macro_f1']:.4f}\")\n",
    "print(f\"  Weighted-F1: {result_lr_answer['test_metrics']['weighted_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-class F1 (Test):\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {label}: {result_lr_answer['per_class_f1'][i]:.4f}\")\n",
    "\n",
    "# --- 4.2 Question-only TF-IDF + Logistic Regression ---\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.2: Question-only TF-IDF + Logistic Regression\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tfidf_question = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf_question = tfidf_question.fit_transform(X_train_questions)\n",
    "X_val_tfidf_question = tfidf_question.transform(X_val_questions)\n",
    "X_test_tfidf_question = tfidf_question.transform(X_test_questions)\n",
    "\n",
    "lr_question = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result_lr_question = evaluate_model(\n",
    "    lr_question, X_train_tfidf_question, y_train,\n",
    "    X_val_tfidf_question, y_val, X_test_tfidf_question, y_test,\n",
    "    \"Logistic Regression\", \"TF-IDF (Question-only)\"\n",
    ")\n",
    "\n",
    "results.append(result_lr_question)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Accuracy:  {result_lr_question['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro-F1:  {result_lr_question['test_metrics']['macro_f1']:.4f}\")\n",
    "print(f\"  Per-class F1: {result_lr_question['per_class_f1']}\")\n",
    "\n",
    "# --- 4.3 Combined Q+A TF-IDF + Logistic Regression ---\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.3: Combined Q+A TF-IDF + Logistic Regression\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tfidf_combined = TfidfVectorizer(\n",
    "    max_features=15000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_tfidf_combined = tfidf_combined.fit_transform(X_train_combined)\n",
    "X_val_tfidf_combined = tfidf_combined.transform(X_val_combined)\n",
    "X_test_tfidf_combined = tfidf_combined.transform(X_test_combined)\n",
    "\n",
    "lr_combined = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result_lr_combined = evaluate_model(\n",
    "    lr_combined, X_train_tfidf_combined, y_train,\n",
    "    X_val_tfidf_combined, y_val, X_test_tfidf_combined, y_test,\n",
    "    \"Logistic Regression\", \"TF-IDF (Q+A Combined)\"\n",
    ")\n",
    "\n",
    "results.append(result_lr_combined)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Accuracy:  {result_lr_combined['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro-F1:  {result_lr_combined['test_metrics']['macro_f1']:.4f}\")\n",
    "print(f\"  Per-class F1: {result_lr_combined['per_class_f1']}\")\n",
    "\n",
    "# --- 4.4 Hyperparameter Tuning for Best TF-IDF Config ---\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.4: Hyperparameter Tuning (TF-IDF + LR)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search over key hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'max_features': [5000, 10000, 15000],\n",
    "    'ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "for C in param_grid['C']:\n",
    "    for max_feat in param_grid['max_features']:\n",
    "        for ngram in param_grid['ngram_range']:\n",
    "            # Create TF-IDF\n",
    "            tfidf = TfidfVectorizer(\n",
    "                max_features=max_feat,\n",
    "                ngram_range=ngram,\n",
    "                min_df=2,\n",
    "                max_df=0.95,\n",
    "                stop_words='english'\n",
    "            )\n",
    "            \n",
    "            X_train_tune = tfidf.fit_transform(X_train_combined)\n",
    "            X_val_tune = tfidf.transform(X_val_combined)\n",
    "            \n",
    "            # Train LR\n",
    "            lr = LogisticRegression(\n",
    "                C=C,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced',\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            lr.fit(X_train_tune, y_train)\n",
    "            y_val_pred = lr.predict(X_val_tune)\n",
    "            val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "            \n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                best_config = {'C': C, 'max_features': max_feat, 'ngram_range': ngram}\n",
    "                best_model = lr\n",
    "                best_tfidf = tfidf\n",
    "\n",
    "print(f\"\\n✅ Best configuration found:\")\n",
    "print(f\"  C: {best_config['C']}\")\n",
    "print(f\"  max_features: {best_config['max_features']}\")\n",
    "print(f\"  ngram_range: {best_config['ngram_range']}\")\n",
    "print(f\"  Best val macro-F1: {best_val_f1:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "X_test_tune = best_tfidf.transform(X_test_combined)\n",
    "y_test_pred_tuned = best_model.predict(X_test_tune)\n",
    "test_f1_tuned = f1_score(y_test, y_test_pred_tuned, average='macro')\n",
    "\n",
    "result_lr_tuned = {\n",
    "    'model_name': 'Logistic Regression (Tuned)',\n",
    "    'feature_type': 'TF-IDF (Q+A Combined)',\n",
    "    'val_metrics': {'macro_f1': best_val_f1},\n",
    "    'test_metrics': {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred_tuned),\n",
    "        'macro_f1': test_f1_tuned,\n",
    "        'weighted_f1': f1_score(y_test, y_test_pred_tuned, average='weighted')\n",
    "    },\n",
    "    'per_class_f1': f1_score(y_test, y_test_pred_tuned, average=None),\n",
    "    'y_test_pred': y_test_pred_tuned,\n",
    "    'model': best_model\n",
    "}\n",
    "\n",
    "results.append(result_lr_tuned)\n",
    "\n",
    "print(f\"\\nTest Metrics (Tuned):\")\n",
    "print(f\"  Accuracy:  {result_lr_tuned['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Macro-F1:  {result_lr_tuned['test_metrics']['macro_f1']:.4f}\")\n",
    "print(f\"  Per-class F1: {result_lr_tuned['per_class_f1']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: XGBOOST BASELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SECTION 5: TF-IDF + XGBOOST BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not XGBOOST_AVAILABLE:\n",
    "    print(\"⚠️ Skipping XGBoost - library not available\")\n",
    "else:\n",
    "    # --- 5.1 Basic XGBoost ---\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"5.1: XGBoost with TF-IDF (Combined Q+A)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    result_xgb = evaluate_model(\n",
    "        xgb_model, X_train_tfidf_combined, y_train,\n",
    "        X_val_tfidf_combined, y_val, X_test_tfidf_combined, y_test,\n",
    "        \"XGBoost\", \"TF-IDF (Q+A Combined)\"\n",
    "    )\n",
    "    \n",
    "    results.append(result_xgb)\n",
    "    \n",
    "    print(f\"\\nTest Metrics:\")\n",
    "    print(f\"  Accuracy:  {result_xgb['test_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  Macro-F1:  {result_xgb['test_metrics']['macro_f1']:.4f}\")\n",
    "    print(f\"  Per-class F1: {result_xgb['per_class_f1']}\")\n",
    "    \n",
    "    # --- 5.2 Feature Importance Analysis ---\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"5.2: XGBoost Feature Importance\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance_dict = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "    \n",
    "    # Map feature indices to names\n",
    "    feature_names = tfidf_combined.get_feature_names_out()\n",
    "    \n",
    "    # Sort by importance\n",
    "    sorted_importance = sorted(\n",
    "        [(feature_names[int(k[1:])], v) for k, v in importance_dict.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:20]\n",
    "    \n",
    "    print(\"\\nTop 20 most important features:\")\n",
    "    for i, (feature, importance) in enumerate(sorted_importance, 1):\n",
    "        print(f\"  {i:2d}. {feature}: {importance:.2f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features, importances = zip(*sorted_importance[:15])\n",
    "    ax.barh(range(len(features)), importances, align='center')\n",
    "    ax.set_yticks(range(len(features)))\n",
    "    ax.set_yticklabels(features)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Feature Importance (Weight)', fontsize=12)\n",
    "    ax.set_title('XGBoost Top 15 Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('notebooks/figures/04_xgboost_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # --- 5.3 XGBoost Hyperparameter Tuning ---\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"5.3: XGBoost Hyperparameter Tuning\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    best_xgb_val_f1 = 0\n",
    "    best_xgb_config = None\n",
    "    best_xgb_model = None\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    \n",
    "    print(\"Performing grid search (simplified)...\")\n",
    "    for max_depth in [4, 6, 8]:\n",
    "        for lr in [0.05, 0.1]:\n",
    "            xgb_tune = xgb.XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=lr,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                eval_metric='mlogloss',\n",
    "                use_label_encoder=False\n",
    "            )\n",
    "            \n",
    "            xgb_tune.fit(X_train_tfidf_combined, y_train)\n",
    "            y_val_pred = xgb_tune.predict(X_val_tfidf_combined)\n",
    "            val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "            \n",
    "            if val_f1 > best_xgb_val_f1:\n",
    "                best_xgb_val_f1 = val_f1\n",
    "                best_xgb_config = {'max_depth': max_depth, 'learning_rate': lr}\n",
    "                best_xgb_model = xgb_tune\n",
    "    \n",
    "    print(f\"\\n✅ Best XGBoost configuration:\")\n",
    "    print(f\"  max_depth: {best_xgb_config['max_depth']}\")\n",
    "    print(f\"  learning_rate: {best_xgb_config['learning_rate']}\")\n",
    "    print(f\"  Best val macro-F1: {best_xgb_val_f1:.4f}\")\n",
    "    \n",
    "    # Evaluate on test\n",
    "    y_test_pred_xgb = best_xgb_model.predict(X_test_tfidf_combined)\n",
    "    \n",
    "    result_xgb_tuned = {\n",
    "        'model_name': 'XGBoost (Tuned)',\n",
    "        'feature_type': 'TF-IDF (Q+A Combined)',\n",
    "        'val_metrics': {'macro_f1': best_xgb_val_f1},\n",
    "        'test_metrics': {\n",
    "            'accuracy': accuracy_score(y_test, y_test_pred_xgb),\n",
    "            'macro_f1': f1_score(y_test, y_test_pred_xgb, average='macro'),\n",
    "            'weighted_f1': f1_score(y_test, y_test_pred_xgb, average='weighted')\n",
    "        },\n",
    "        'per_class_f1': f1_score(y_test, y_test_pred_xgb, average=None),\n",
    "        'y_test_pred': y_test_pred_xgb,\n",
    "        'model': best_xgb_model\n",
    "    }\n",
    "    \n",
    "    results.append(result_xgb_tuned)\n",
    "    \n",
    "    print(f\"\\nTest Metrics (Tuned XGBoost):\")\n",
    "    print(f\"  Accuracy:  {result_xgb_tuned['test_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  Macro-F1:  {result_xgb_tuned['test_metrics']['macro_f1']:.4f}\")\n",
    "    print(f\"  Per-class F1: {result_xgb_tuned['per_class_f1']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: ENGINEERED FEATURES EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SECTION 6: ENGINEERED FEATURES EXTRACTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nExtracting engineered features (this may take a few minutes)...\")\n",
    "\n",
    "def extract_features_batch(questions, answers, desc=\"Extracting\"):\n",
    "    \"\"\"Extract features for a batch of Q-A pairs.\"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for q, a in tqdm(zip(questions, answers), total=len(questions), desc=desc):\n",
    "        features = extract_all_features(q, a, include_q_features=True)\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# Extract features for all splits\n",
    "print(\"\\nExtracting train features...\")\n",
    "train_features_df = extract_features_batch(X_train_questions, X_train_answers, \"Train\")\n",
    "\n",
    "print(\"\\nExtracting val features...\")\n",
    "val_features_df = extract_features_batch(X_val_questions, X_val_answers, \"Val\")\n",
    "\n",
    "print(\"\\nExtracting test features...\")\n",
    "test_features_df = extract_features_batch(X_test_questions, X_test_answers, \"Test\")\n",
    "\n",
    "print(f\"\\n✅ Feature extraction complete\")\n",
    "print(f\"  Train features shape: {train_features_df.shape}\")\n",
    "print(f\"  Val features shape: {val_features_df.shape}\")\n",
    "print(f\"  Test features shape: {test_features_df.shape}\")\n",
    "\n",
    "# Display feature names\n",
    "print(f\"\\nFeature names ({len(train_features_df.columns)} total):\")\n",
    "for i, col in enumerate(train_features_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Handle missing values\n",
    "train_features_df = train_features_df.fillna(0)\n",
    "val_features_df = val_features_df.fillna(0)\n",
    "test_features_df = test_features_df.fillna(0)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_eng = scaler.fit_transform(train_features_df)\n",
    "X_val_eng = scaler.transform(val_features_df)\n",
    "X_test_eng = scaler.transform(test_features_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
